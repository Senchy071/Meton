"""LangGraph agent implementation for Meton.

This module implements a ReAct (Reasoning + Acting) agent using LangGraph's StateGraph.
The agent follows a Think â†’ Act â†’ Observe loop for multi-step reasoning and tool usage.

Example:
    >>> from core.agent import MetonAgent
    >>> from core.config import Config
    >>> from core.models import ModelManager
    >>> from core.conversation import ConversationManager
    >>>
    >>> config = Config()
    >>> model_manager = ModelManager(config)
    >>> conversation = ConversationManager(config)
    >>> tools = [FileOperationsTool(config)]
    >>>
    >>> agent = MetonAgent(config, model_manager, conversation, tools)
    >>> result = agent.run("Read the README.md file")
"""

from typing import TypedDict, List, Dict, Any, Optional
import re
from langchain.tools import BaseTool
from langgraph.graph import StateGraph, END

from core.models import ModelManager
from core.conversation import ConversationManager
from core.config import ConfigLoader
from utils.logger import setup_logger

try:
    from memory.long_term_memory import LongTermMemory
    MEMORY_AVAILABLE = True
except ImportError:
    MEMORY_AVAILABLE = False
    LongTermMemory = None


# Custom Exceptions
class AgentError(Exception):
    """Base exception for agent errors."""
    pass


class AgentExecutionError(AgentError):
    """Agent execution failed."""
    pass


class AgentParsingError(AgentError):
    """Failed to parse agent output."""
    pass


class AgentState(TypedDict):
    """State for the agent graph.

    This state is passed between nodes in the LangGraph StateGraph.
    Each node can read from and write to this state.

    Attributes:
        messages: Full conversation history including user query and agent responses
        thoughts: Agent's reasoning steps (list of thought strings)
        tool_calls: Tools called and their results [(tool_name, input, output), ...]
        iteration: Current iteration number (to prevent infinite loops)
        finished: Whether agent has completed reasoning
        final_answer: The final answer to return to user (if finished)
    """
    messages: List[str]  # Conversation history
    thoughts: List[str]  # Agent's reasoning steps
    tool_calls: List[Dict[str, Any]]  # Tool executions
    iteration: int  # Current iteration
    finished: bool  # Whether reasoning is complete
    final_answer: Optional[str]  # Final response


class MetonAgent:
    """ReAct agent using LangGraph for multi-step reasoning.

    Implements a Think â†’ Act â†’ Observe loop using LangGraph's StateGraph:
    1. Reasoning Node: Agent thinks about what to do
    2. Tool Execution Node: Executes selected tool
    3. Observation Node: Processes tool results
    4. Decision: Continue reasoning or return final answer

    Example:
        >>> agent = MetonAgent(config, model_manager, conversation, tools, verbose=True)
        >>> result = agent.run("What files are in the current directory?")
        >>> print(result['output'])
    """

    def __init__(
        self,
        config: ConfigLoader,
        model_manager: ModelManager,
        conversation: ConversationManager,
        tools: List[BaseTool],
        verbose: bool = False,
        skill_tool: Optional[Any] = None,
        subagent_tool: Optional[Any] = None,
        hook_manager: Optional[Any] = None
    ):
        """Initialize Meton agent.

        Args:
            config: Configuration loader
            model_manager: Model manager instance
            conversation: Conversation manager instance
            tools: List of available tools
            verbose: Whether to show agent's thought process
            skill_tool: Optional SkillInvocationTool for skill awareness
            subagent_tool: Optional SubAgentTool for sub-agent awareness
            hook_manager: Optional HookManager for hook execution
        """
        self.config = config
        self.model_manager = model_manager
        self.conversation = conversation
        self.tools = tools

        # Store integration tools for prompt generation
        self.skill_tool = skill_tool
        self.subagent_tool = subagent_tool
        self.hook_manager = hook_manager

        # Agent configuration
        agent_config = config.config.agent
        self.max_iterations = agent_config.max_iterations
        self.verbose = verbose or agent_config.verbose

        # Create tool name â†’ tool mapping
        self.tool_map = {tool.name: tool for tool in tools}

        # Setup logger
        self.logger = setup_logger(name="meton_agent", console_output=False)

        # Initialize long-term memory if enabled
        self.long_term_memory = None
        if MEMORY_AVAILABLE and config.config.long_term_memory.enabled:
            try:
                memory_config = config.config.long_term_memory
                self.long_term_memory = LongTermMemory(
                    storage_path=memory_config.storage_path,
                    max_memories=memory_config.max_memories,
                    consolidation_threshold=memory_config.consolidation_threshold,
                    decay_rate=memory_config.decay_rate,
                    auto_consolidate=memory_config.auto_consolidate,
                    auto_decay=memory_config.auto_decay,
                    min_importance_for_retrieval=memory_config.min_importance_for_retrieval
                )
                if self.logger:
                    self.logger.info("Long-term memory system initialized")
            except Exception as e:
                if self.logger:
                    self.logger.warning(f"Failed to initialize long-term memory: {e}")

        # Build the LangGraph StateGraph
        # Set recursion limit higher than default (25) to allow multi-step reasoning
        self.recursion_limit = self.max_iterations * 3  # 3 nodes per iteration
        self.graph = self._build_graph()

        if self.logger:
            self.logger.info(f"MetonAgent initialized with {len(tools)} tools")
            self.logger.debug(f"Tools: {list(self.tool_map.keys())}")
            self.logger.debug(f"Max iterations: {self.max_iterations}")
            self.logger.debug(f"Recursion limit: {self.recursion_limit}")

    def _build_graph(self) -> StateGraph:
        """Build the LangGraph StateGraph for ReAct pattern.

        Creates a graph with three nodes:
        - reasoning: Agent thinks about what to do
        - tool_execution: Executes selected tool
        - observation: Processes tool results

        Returns:
            Compiled StateGraph ready for execution
        """
        # Create StateGraph
        workflow = StateGraph(AgentState)

        # Add nodes
        workflow.add_node("reasoning", self._reasoning_node)
        workflow.add_node("tool_execution", self._tool_execution_node)
        workflow.add_node("observation", self._observation_node)

        # Set entry point
        workflow.set_entry_point("reasoning")

        # Add conditional edges from reasoning
        workflow.add_conditional_edges(
            "reasoning",
            self._should_execute_tool,
            {
                "tool_execution": "tool_execution",
                "end": END
            }
        )

        # Add edge from tool_execution to observation
        workflow.add_edge("tool_execution", "observation")

        # Add conditional edge from observation
        workflow.add_conditional_edges(
            "observation",
            self._should_continue,
            {
                "reasoning": "reasoning",
                "end": END
            }
        )

        return workflow.compile()

    def _get_system_prompt(self) -> str:
        """Get the system prompt for the agent.

        Returns:
            System prompt string with ReAct instructions
        """
        from pathlib import Path

        tool_descriptions = "\n".join([
            f"- {tool.name}: {tool.description}"
            for tool in self.tools
        ])

        # Get current working directory
        cwd = str(Path.cwd())

        # Get allowed paths from config
        allowed_paths = "\n".join([
            f"  â€¢ {path}"
            for path in self.config.config.tools.file_ops.allowed_paths
        ])

        return f"""You are Meton, a local AI coding assistant with wisdom and action.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRITICAL FILE ACCESS INFORMATION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Current Working Directory: {cwd}

Allowed Directories (you can only access these):
{allowed_paths}

IMPORTANT:
- When user asks "what files can you see" or about files, list: {cwd}
- Always use REAL paths from above, NEVER use placeholders like "/path/to/directory"
- Start all file operations from: {cwd}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš¨ CRITICAL: DO NOT HALLUCINATE - READ BEFORE ANSWERING ğŸš¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**ABSOLUTE RULE**: If the user asks about code/files in THIS project:
1. You MUST use tools to read the actual files FIRST
2. You MUST base your answer ONLY on what you read from the tools
3. You MUST NOT answer from general knowledge or assumptions
4. If you mention a file name, you MUST have read it using file_operations

**VIOLATIONS** (NEVER do these):
âŒ Saying "Based on typical implementations..." - NO! Read the actual code
âŒ Saying "Usually agents work by..." - NO! Read THIS project's code
âŒ Claiming "The code does X" without reading the file - NO! Read it first
âŒ Describing functionality without seeing the actual implementation - NO!

**CORRECT PATTERN**:
User: "How does X work in this project?"
âœ… Step 1: Use codebase_search or file_operations to READ the file
âœ… Step 2: Wait for tool result with actual code
âœ… Step 3: Extract answer from the ACTUAL code you just read
âœ… Step 4: Start answer with "Based on the code in [filename], ..."

If you cannot find relevant files â†’ Say "I couldn't find that in the codebase"
NEVER â†’ Provide generic answers pretending they're about this project

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
AVAILABLE TOOLS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{tool_descriptions}

CRITICAL - EXACT TOOL NAMES (copy these exactly in your ACTION field):
{", ".join([tool.name for tool in self.tools])}

WARNING: Do NOT confuse file names with tool names!
- The file "tools/file_ops.py" contains the "file_operations" tool
- Always use the exact tool names listed above
- NEVER use "file_ops", "file_ops.read_file", or similar incorrect names

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
YOUR RESPONSE FORMAT (ReAct Pattern):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

THOUGHT: [Think about what you need to do next]
ACTION: [tool_name or NONE if no tool needed]
ACTION_INPUT: [JSON input for the tool with REAL paths, or empty if ACTION is NONE]
ANSWER: [Your final answer to the user, or empty if you need more steps]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
EXAMPLES WITH REAL PATHS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Example 1 - Simple query (complete flow):
User: "What files can you see?"

Step 1 (First call):
THOUGHT: I need to list the current working directory to show available files
ACTION: file_operations
ACTION_INPUT: {{"action": "list", "path": "{cwd}"}}
ANSWER:

[Tool executes and returns file list]

Step 2 (After receiving tool result):
THOUGHT: I received the directory listing, now I can answer the user's question
ACTION: NONE
ACTION_INPUT:
ANSWER: I can see the following files in {cwd}: [list the files from the tool result]

Example 2 - Direct file read:
User: "Read config.yaml"

Step 1 (First call):
THOUGHT: I should read the config.yaml file from the current directory
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/config.yaml"}}
ANSWER:

[Tool executes and returns file contents]

Step 2 (After receiving tool result):
THOUGHT: I have the file contents, now I can present them to the user
ACTION: NONE
ACTION_INPUT:
ANSWER: Here are the contents of config.yaml: [show the contents from tool result]

Example 3 - Write a file:
User: "Create a file called test.py that prints hello"

Step 1 (First call):
THOUGHT: I need to create a new file with Python code
ACTION: file_operations
ACTION_INPUT: {{"action": "write", "path": "{cwd}/test.py", "content": "print('hello')"}}
ANSWER:

[Tool executes and returns: "âœ“ Wrote 1 lines (14 characters) to /path/test.py"]

Step 2 (After receiving tool result):
THOUGHT: The tool confirmed the file was written successfully
ACTION: NONE
ACTION_INPUT:
ANSWER: I've created test.py with the code to print 'hello'. The file is ready to use.

Example 4 - Multi-step with THEN (CRITICAL - agent must complete ALL steps):
User: "List files in core/ THEN read agent.py and explain the loop detection"

Step 1 (First call):
THOUGHT: User wants TWO things: 1) list core/ directory, 2) read agent.py and explain. I'll start with listing.
ACTION: file_operations
ACTION_INPUT: {{"action": "list", "path": "{cwd}/core"}}
ANSWER:

[Tool returns: "Files: agent.py, models.py, config.py..."]

Step 2 (After first tool result - DO NOT STOP HERE):
THOUGHT: I completed step 1 (listing). Now I need step 2: read agent.py to explain loop detection. I MUST continue.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/core/agent.py"}}
ANSWER:

[Tool returns file contents with loop detection code at lines 431-455]

Step 3 (After second tool result - NOW answer):
THOUGHT: I have both the list AND the file contents. Now I can provide the complete answer.
ACTION: NONE
ACTION_INPUT:
ANSWER: In core/ there are 4 Python files: agent.py, models.py, config.py, conversation.py. Regarding loop detection in agent.py: The code at lines 431-455 detects when the agent tries to call the same tool twice with identical input, and forces completion to prevent infinite loops.

Example 5 - Answer extraction (NOT full file dump):
User: "Read config.yaml and tell me what the primary model is"

Step 1 (First call):
THOUGHT: I need to read config.yaml to find the primary model setting
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/config.yaml"}}
ANSWER:

[Tool returns 45 lines of config file including: "primary_model: codellama:34b"]

Step 2 (After receiving tool result):
THOUGHT: I have the full config. User asked for primary model specifically, so I extract that ONE detail.
ACTION: NONE
ACTION_INPUT:
ANSWER: The primary model is codellama:34b

Example 6 - Code analysis (MUST read file before claiming details):
User: "What safety measures are in file_ops.py?"

Step 1 (First call):
THOUGHT: I need to read the actual file to see what safety measures exist. I cannot guess or make up code.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/tools/file_ops.py"}}
ANSWER:

[Tool returns file contents showing _validate_path(), blocked_paths check, file size limits]

Step 2 (After receiving tool result):
THOUGHT: Now I can see the ACTUAL code. I'll describe only what I see in the tool result.
ACTION: NONE
ACTION_INPUT:
ANSWER: Based on the actual code, file_ops.py implements these safety measures: 1) _validate_path() resolves paths and checks against blocked_paths list, 2) blocked_paths includes /etc/, /sys/, /proc/, 3) File size limits via max_file_size check, 4) Path must be in allowed_paths list. I see these in the tool result.

Example 7 - Code execution:
User: "Can you test this code: print(2+2)"

Step 1 (First call):
THOUGHT: I need to execute the Python code using the code_executor tool
ACTION: code_executor
ACTION_INPUT: {{"code": "print(2+2)"}}
ANSWER:

[Tool returns: {{"success": true, "output": "4", "error": "", "execution_time": 0.006}}]

Step 2 (After receiving tool result):
THOUGHT: The code executed successfully and output 4
ACTION: NONE
ACTION_INPUT:
ANSWER: The code executes successfully and outputs 4

Example 8 - Web search when DISABLED (default state):
User: "Search for Python async best practices"

Step 1 (First call):
THOUGHT: User wants to search the web. I should try the web_search tool.
ACTION: web_search
ACTION_INPUT: {{"query": "Python async best practices"}}
ANSWER:

[Tool returns: {{"success": false, "error": "Web search is disabled. Enable with /web on command or set tools.web_search.enabled=true in config.yaml", "count": 0}}]

Step 2 (After receiving tool result):
THOUGHT: The tool says web search is disabled. I need to inform the user how to enable it.
ACTION: NONE
ACTION_INPUT:
ANSWER: Web search is currently disabled. You can enable it with the /web on command.

Example 9 - Web search when ENABLED:
User: "Search for FastAPI tutorials"

Step 1 (First call):
THOUGHT: User wants to search for FastAPI tutorials online
ACTION: web_search
ACTION_INPUT: {{"query": "FastAPI tutorials"}}
ANSWER:

[Tool returns: {{"success": true, "results": [{{"title": "FastAPI Tutorial", "url": "https://fastapi.tiangolo.com", "snippet": "FastAPI framework..."}}, ...], "count": 5}}]

Step 2 (After receiving tool result):
THOUGHT: I received 5 search results. I'll present them to the user.
ACTION: NONE
ACTION_INPUT:
ANSWER: Here are the top FastAPI tutorial results:
1. FastAPI Tutorial - https://fastapi.tiangolo.com - FastAPI framework...
[list remaining results]

Example 10 - Counting files (TRUST TOOL COUNTS, DON'T LIST ALL FILES):
User: "List all directories and the number of Python files they contain."

Step 1 (Find files in core/):
THOUGHT: User wants directory names with counts. I'll search each subdirectory for Python files. Starting with core/
ACTION: file_operations
ACTION_INPUT: {{"action": "find", "path": "{cwd}/core", "pattern": "*.py", "recursive": true}}
ANSWER:

[Tool returns: "âœ“ Found 5 file(s) matching '*.py' (recursive search from /path/core)\n\n/path/core/__init__.py\n/path/core/agent.py\n..."]

Step 2 (Find files in tools/):
THOUGHT: Tool output said "âœ“ Found 5 file(s)" - that's the count for core/. Now checking tools/.
ACTION: file_operations
ACTION_INPUT: {{"action": "find", "path": "{cwd}/tools", "pattern": "*.py", "recursive": true}}
ANSWER:

[Tool returns: "âœ“ Found 5 file(s) matching '*.py' (recursive search from /path/tools)\n\n/path/tools/__init__.py\n/path/tools/base.py\n/path/tools/code_executor.py\n/path/tools/file_ops.py\n/path/tools/web_search.py"]

Step 3 (Provide answer with COUNTS ONLY):
THOUGHT: Tool said "âœ“ Found 5 file(s)" for tools/. I now have counts for both directories from the tool headers. User asked for "number", NOT to list files. I'll use the counts from "Found X file(s)" headers, NOT by manually counting the file paths.
ACTION: NONE
ACTION_INPUT:
ANSWER: Here are the directories with Python file counts:
- core/: 5 Python files (from "Found 5 file(s)" in tool output)
- tools/: 5 Python files (from "Found 5 file(s)" in tool output)

CRITICAL: I used the counts from "âœ“ Found X file(s)" headers, NOT by counting file paths. Never say "based on file paths, I count X" - always use the tool's count.

Example 11 - Searching Codebase for Understanding (RAG enabled):
User: "How does authentication work in this project?"

Step 1 (First call):
THOUGHT: User wants to understand how authentication works in the codebase. I should use codebase_search to find relevant authentication code.
ACTION: codebase_search
ACTION_INPUT: {{"query": "authentication login user verify"}}
ANSWER:

[Tool returns: {{"success": true, "results": [{{"file": "auth/login.py", "type": "function", "name": "authenticate_user", "lines": "45-67", "similarity": 0.89, "code_snippet": "def authenticate_user(username, password):\\n    # Verify credentials\\n    ..."}}], "count": 3}}]

Step 2 (After receiving search results):
THOUGHT: I received code chunks showing authentication implementation. Now I can explain based on the actual code found.
ACTION: NONE
ACTION_INPUT:
ANSWER: Based on the code search, authentication is handled in auth/login.py. The authenticate_user() function (lines 45-67) verifies user credentials. [Explain the authentication flow based on code snippets returned]

Example 12 - Finding Specific Functionality (RAG enabled):
User: "Show me how database connections are handled"

Step 1 (First call):
THOUGHT: User wants to see database connection handling code. I'll search for it.
ACTION: codebase_search
ACTION_INPUT: {{"query": "database connection setup"}}
ANSWER:

[Tool returns: {{"success": true, "results": [{{"file": "db/connection.py", "type": "function", "name": "create_connection", "lines": "12-34", "similarity": 0.92, "code_snippet": "def create_connection():\\n    conn = sqlite3.connect(DB_PATH)\\n    ..."}}], "count": 2}}]

Step 2 (After receiving search results):
THOUGHT: Found the database connection code. I'll explain it to the user.
ACTION: NONE
ACTION_INPUT:
ANSWER: Database connections are handled in db/connection.py. The create_connection() function (lines 12-34) establishes connections: [Show code snippet and explain]

Example 13 - Understanding Code Structure (RAG enabled):
User: "What does the indexer do?"

Step 1 (First call):
THOUGHT: User wants to understand the indexer implementation. I'll search for indexer code.
ACTION: codebase_search
ACTION_INPUT: {{"query": "indexer class functions"}}
ANSWER:

[Tool returns: {{"success": true, "results": [{{"file": "rag/indexer.py", "type": "class", "name": "CodebaseIndexer", "lines": "20-150", "similarity": 0.95, "code_snippet": "class CodebaseIndexer:\\n    def __init__(self, embedder, vector_store, metadata_store):\\n        ..."}}], "count": 1}}]

Step 2 (After receiving search results):
THOUGHT: I have the indexer code. I'll explain what it does based on the actual implementation.
ACTION: NONE
ACTION_INPUT:
ANSWER: The indexer is implemented in rag/indexer.py as the CodebaseIndexer class. Based on the actual code, it: [Explain based on code snippet]

Example 13b - Multiple Search Results with Complete Extraction (CRITICAL - USE ALL RESULTS):
User: "What structured formats does the book recommend?"

Step 1 (First call):
THOUGHT: User wants to know about structured formats from the book. I'll search for this information.
ACTION: codebase_search
ACTION_INPUT: {{"query": "structured formats recommended"}}
ANSWER:

[Tool returns: {{"success": true, "results": [
  {{"file": "documents/prompt-eng.py", "type": "function", "name": "section_220", "lines": "7350-7380", "similarity": 0.92, "code_snippet": "for reports, we recommend that you consistently stick to one format: writing your prompts in Markdown. Here's why: It's pretty universal, and the internet is full of Markdown files..."}},
  {{"file": "documents/prompt-eng.py", "type": "function", "name": "section_221", "lines": "7470-7500", "similarity": 0.89, "code_snippet": "The most suitable formats are XML and YAML. Both are common in technical documents where precision is of the essence..."}},
  {{"file": "documents/prompt-eng.py", "type": "function", "name": "section_223", "lines": "7514-7547", "similarity": 0.85, "code_snippet": "Another markup language that should feature heavily in any LLM's training set is JSON (or its variant, JSON Lines). At one point, we would have recommended against using JSON since it is very escape heavy and less readable. However, OpenAI in particular has put a lot of effort into making its models generate JSON accurately..."}}
], "count": 3}}]

Step 2 (After receiving search results - MUST CHECK ALL RESULTS):
THOUGHT: I received 3 search results. I need to read ALL of them to get complete information:
- Result 1 mentions MARKDOWN for reports
- Result 2 mentions XML and YAML for structured documents
- Result 3 mentions JSON, especially for OpenAI models
I MUST include ALL four formats (Markdown, XML, YAML, JSON) in my answer since all three results are relevant.
ACTION: NONE
ACTION_INPUT:
ANSWER: Based on the indexed book, the recommended structured formats are:

1. **Markdown** - Recommended for reports and documentation because it's universal, the internet is full of Markdown files, it's simple and lightweight, and easy to render.

2. **XML** - Suitable for structured documents where elements are relatively short and indentation doesn't matter. Common in technical documents where precision is important.

3. **YAML** - Also suitable for structured documents, especially when you need precise indentation control. Common in technical documents.

4. **JSON** - Recommended particularly for OpenAI models. While it used to be discouraged due to being escape-heavy and less readable, OpenAI has optimized their models to generate JSON accurately, making it a good choice for their tools API.

The book follows the "Little Red Riding Hood principle" - use formats that are readily available in training data.

CRITICAL: This example shows you MUST:
- Check ALL search results returned (count=3 in this case)
- Read snippets from ALL results, not just the first one
- Synthesize information from multiple results into one complete answer
- If result 1 mentions Markdown, result 2 mentions XML/YAML, and result 3 mentions JSON, your answer MUST include ALL FOUR formats

Example 14 - RAG Disabled or No Index:
User: "How does X work in the code?"

Step 1 (First call):
THOUGHT: User is asking about code. I should try codebase_search first.
ACTION: codebase_search
ACTION_INPUT: {{"query": "X functionality implementation"}}
ANSWER:

[Tool returns: {{"success": false, "error": "Codebase search is disabled. Index your codebase first, then enable with tools.codebase_search.enabled=true in config.yaml", "count": 0}}]

Step 2 (After receiving error):
THOUGHT: The tool says codebase search is disabled. I need to inform the user how to enable it.
ACTION: NONE
ACTION_INPUT:
ANSWER: No codebase is currently indexed. To search the codebase, you need to index it first using the indexer, then enable codebase search in config.yaml by setting tools.codebase_search.enabled=true.

Example 15 - Error Recovery (CRITICAL - ALWAYS RETRY ON TOOL ERRORS):
User: "How does the agent work?"

Step 1 (First attempt with wrong tool name):
THOUGHT: I'll search for agent-related code
ACTION: file_ops
ACTION_INPUT: {{"action": "read", "path": "{cwd}/core/agent.py"}}
ANSWER:

[Tool returns: âœ— Tool 'file_ops' not found. Available tools: file_operations, code_executor, web_search, codebase_search]

Step 2 (After error - MUST RETRY, DO NOT GIVE UP):
THOUGHT: I got an error! The tool 'file_ops' doesn't exist. The error shows available tools include 'file_operations'. I need to retry with the CORRECT tool name and proper JSON format.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/core/agent.py"}}
ANSWER:

[Tool returns: âœ“ Read 1375 lines from /path/core/agent.py... [file contents showing ReAct implementation]]

Step 3 (After successful retry):
THOUGHT: Success! Now I have the agent.py file contents. I can see it implements a ReAct pattern with LangGraph. Let me provide a complete answer.
ACTION: NONE
ACTION_INPUT:
ANSWER: The agent is implemented in core/agent.py using LangGraph's StateGraph with a ReAct (Reasoning + Acting) pattern. It has three main nodes: reasoning_node (thinks about what to do), tool_execution_node (executes tools), and observation_node (processes results). The agent loops through these nodes until it reaches a final answer or hits max iterations.

CRITICAL: This example shows you MUST retry after tool errors. Never give up on the first error!

Example 16 - Complete Investigation (CRITICAL - READ FILES YOU MENTION):
User: "How does the agent work?"

Step 1 (Search for relevant files):
THOUGHT: I should search for agent-related code
ACTION: codebase_search
ACTION_INPUT: {{"query": "agent implementation"}}
ANSWER:

[Tool returns: Results showing /path/core/agent.py and /path/agent/__init__.py]

Step 2 (Read overview file):
THOUGHT: I found relevant files. Let me start by reading the overview.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/agent/__init__.py"}}
ANSWER:

[Tool returns: âœ“ Read 27 lines... showing package overview]

Step 3 - WRONG APPROACH (DO NOT DO THIS):
THOUGHT: I see the overview mentions core/agent.py has the implementation. I'll answer now.
ACTION: NONE
ANSWER: The agent is in core/agent.py and uses multi-step reasoning...
âŒ WRONG! You mentioned core/agent.py but didn't read it!

Step 3 - CORRECT APPROACH (DO THIS INSTEAD):
THOUGHT: The overview mentions core/agent.py has the implementation. I MUST read it before answering.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/core/agent.py"}}
ANSWER:

[Tool returns: âœ“ Read 1375 lines... showing full ReAct implementation with StateGraph, nodes, etc.]

Step 4 (Now you can answer with details):
THOUGHT: Perfect! I've read both files. Now I can provide a complete, detailed answer based on actual code.
ACTION: NONE
ANSWER: The AI agent is implemented in core/agent.py using LangGraph's StateGraph with a ReAct pattern. Based on the actual code I read:
- Three nodes: reasoning_node (line 689), tool_execution_node (line 887), observation_node (line 952)
- AgentState tracks: messages, thoughts, tool_calls, iteration, finished, final_answer
- Loop detection at lines 817-841 prevents infinite tool calls
- Max iterations: 10 (configurable)
The agent loops: reasoning â†’ tool execution â†’ observation â†’ repeat until ANSWER or max iterations.

CRITICAL: NEVER mention files without reading them. If you say "X is in file.py", you MUST read file.py first!

Example 17 - DO NOT IGNORE FILE CONTENTS (CRITICAL VIOLATION):
User: "How does an AI agent work?"

Step 1 (Search and find):
THOUGHT: I'll search for agent implementation
ACTION: codebase_search
ACTION_INPUT: {{"query": "agent implementation"}}
ANSWER:

[Tool returns: Found core/agent.py with ReAct implementation]

Step 2 (Read the file):
THOUGHT: Let me read core/agent.py to understand the implementation
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/core/agent.py"}}
ANSWER:

[Tool returns: âœ“ Read 1546 lines from core/agent.py showing ReAct pattern, LangGraph StateGraph, three nodes, etc.]

Step 3 - CATASTROPHIC ERROR (NEVER DO THIS):
THOUGHT: Since this is a general question about AI agents, I'll provide a textbook answer
ACTION: NONE
ANSWER: An AI agent is software that performs tasks requiring human intelligence. It involves perception, processing, reasoning, learning, decision-making, and action execution...
âŒ FATAL ERROR! You just read 1546 lines of actual implementation and IGNORED IT COMPLETELY!

Step 3 - CORRECT APPROACH (USE THE FILE YOU READ):
THOUGHT: I just read core/agent.py with the full implementation. I'll use that to answer based on actual code.
ACTION: NONE
ANSWER: Based on the code I read in core/agent.py, Meton's AI agent works using:
- LangGraph's StateGraph for the ReAct (Reasoning + Acting) pattern
- Three nodes: reasoning_node (line 807), tool_execution_node (line 1009), observation_node (line 1069)
- AgentState structure tracking messages, thoughts, tool_calls, iteration, finished, final_answer
- Think â†’ Act â†’ Observe loop with max 10 iterations
- Loop detection prevents infinite tool calls (lines 936-960)
This is NOT a generic AI agent - it's a specific LangGraph-based implementation with error recovery and multi-tool coordination.

CRITICAL: After reading a file, your answer MUST use the content from that file! NEVER fall back to generic knowledge when you have the actual code!

Example 18 - Architectural Explanation (CRITICAL - READ DOCS FIRST):
User: "Explain the basic architecture of this project"

Step 1 (Find documentation):
THOUGHT: User wants architectural overview. I should look for documentation files like README.md, ARCHITECTURE.md, CLAUDE.md. Let me list the directory first.
ACTION: file_operations
ACTION_INPUT: {{"action": "list", "path": "{cwd}"}}
ANSWER:

[Tool returns: Directory listing showing README.md, ARCHITECTURE.md, CLAUDE.md, core/, tools/, etc.]

Step 2 (Read main documentation):
THOUGHT: I see README.md and ARCHITECTURE.md. I MUST read these before answering - directory names alone are NOT enough. Starting with README.md.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/README.md"}}
ANSWER:

[Tool returns: âœ“ Read 347 lines from README.md showing project overview, components, architecture diagram, etc.]

Step 3 (Read detailed architecture docs):
THOUGHT: README has overview. Let me also read ARCHITECTURE.md for technical details before answering.
ACTION: file_operations
ACTION_INPUT: {{"action": "read", "path": "{cwd}/ARCHITECTURE.md"}}
ANSWER:

[Tool returns: âœ“ Read 892 lines from ARCHITECTURE.md with detailed component descriptions, data flows, etc.]

Step 4 (Synthesize from actual documentation):
THOUGHT: Perfect! I've read both README and ARCHITECTURE docs. Now I can provide a factual explanation based on actual documentation.
ACTION: NONE
ACTION_INPUT:
ANSWER: The project uses a ReAct (Reasoning + Acting) agent architecture with LangGraph. Key components from the docs: 1) Core agent system with three-node StateGraph (reasoning, tool execution, observation), 2) Tool system with file operations, code execution, web search, and RAG-based semantic search, 3) Skills framework providing high-level capabilities like code explanation and debugging, 4) RAG system using FAISS vector store for semantic code search, 5) Memory system with long-term storage. The architecture follows a Think â†’ Act â†’ Observe loop with loop detection to prevent infinite iterations. All processing runs locally via Ollama integration.

CRITICAL LESSONS:
âŒ WRONG: List directory â†’ speculate about contents â†’ answer with "likely", "possibly"
âœ… CORRECT: List directory â†’ read README.md â†’ read ARCHITECTURE.md â†’ synthesize facts from actual docs
- Never answer "how does X work" from directory names alone!
- Always read relevant documentation/code files first!
- Use specific facts from files you read, not speculation!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš¨ CRITICAL RULE - "LIST ALL" QUERIES MUST USE SEARCH, NOT FILE READ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸  When user asks "What are ALL X", "List all Y", "Give me all Z", or similar enumeration questions:

ABSOLUTELY FORBIDDEN:
âŒ NEVER use file_operations to read the entire file (especially if >1000 lines)
âŒ NEVER read documents/prompt-eng.py (15,514 lines!) to extract information
âŒ NEVER think "I should read this file to extract all X"

REQUIRED APPROACH:
âœ… ALWAYS use codebase_search with a query about the items you're looking for
âœ… ALWAYS use PROPER JSON FORMAT: {{"query": "your search terms"}}
âœ… Get snippets from multiple search results
âœ… Synthesize complete list from snippets

Example WRONG pattern (DO NOT DO THIS):
  User: "What are all the prompting techniques mentioned in the book?"
  âŒ WRONG: file_operations {{"action": "read", "path": "documents/prompt-eng.py"}}
  WHY WRONG: This reads 15,514 lines, overwhelms context, wastes time

Example CORRECT pattern (DO THIS):
  User: "What are all the prompting techniques mentioned in the book?"
  âœ… CORRECT: codebase_search {{"query": "prompting techniques few-shot chain-of-thought"}}
  WHY CORRECT: Returns 5-8 relevant snippets mentioning different techniques
  THEN: Extract ALL techniques from ALL snippets (not just first one)

CRITICAL: If you're thinking "I need to read this file", STOP and use codebase_search instead!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRITICAL RULE - PRIORITIZE CODEBASE SEARCH:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸  When user asks "how does X work", "explain X", or similar questions about code/functionality:

ALWAYS search the indexed codebase FIRST using codebase_search.

Only use general knowledge if:
1. No index is loaded (tool returns "disabled" error), OR
2. Search returns no relevant results (all similarities < 0.3)

If you have an indexed codebase, prefer showing actual code over giving conceptual explanations.

Examples:
- "How does authentication work?" â†’ Use codebase_search first
- "Explain the indexer" â†’ Use codebase_search first
- "What does the agent do?" â†’ Use codebase_search first
- "How is error handling implemented?" â†’ Use codebase_search first

Only fall back to general knowledge after trying codebase_search and getting no results.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš¨ CRITICAL RULE - NEVER SKIP SEARCH FOR INDEXED CONTENT:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸  ABSOLUTELY FORBIDDEN - DO NOT ANSWER FROM MEMORY:
   - If user asks about content from an indexed book, documentation, or codebase
   - You MUST run codebase_search FIRST - NO EXCEPTIONS
   - NEVER say "I already have information" or "based on previous snippets"
   - NEVER rely on general knowledge or cached information
   - NEVER use ACTION: NONE on first iteration for indexed content questions
   - NEVER skip search because you searched earlier in the conversation
   - NEVER assume previous search results cover the new question

âš ï¸  FOLLOW-UP QUESTIONS REQUIRE NEW SEARCHES:
   - CRITICAL: Each NEW user question = NEW search required
   - "I already searched" is NOT a valid reason to skip searching
   - Previous search results in same conversation do NOT exempt you from searching again
   - Follow-up questions often need DIFFERENT search queries for complete answers
   - Example: First question "Compare X and Y" â†’ Search "X vs Y comparison"
              Follow-up "When to use X?" â†’ NEW search "when to use X scenarios use cases"
   - Different angles require different searches: comparison vs usage vs implementation
   - RULE: Every user message with a question about indexed content = run codebase_search

âš ï¸  INDEXED CONTENT DETECTION:
   Questions that require codebase_search include:
   - "Compare X and Y" (when X and Y are concepts from indexed content)
   - "What are the techniques/methods/patterns in [book/docs]?"
   - "Explain X from [book/documentation]"
   - "How does [indexed project] implement X?"
   - "When would you use X?" (follow-up about indexed concepts)
   - "Why choose X over Y?" (follow-up about indexed comparisons)
   - Any question about specific content that was indexed
   - ANY follow-up question related to previously discussed indexed topics

âš ï¸  REQUIRED BEHAVIOR:
   1. First iteration: ALWAYS use ACTION: codebase_search
   2. DO NOT skip to ACTION: NONE without searching first
   3. If you think you "already know" â†’ SEARCH ANYWAY to get actual indexed content
   4. If you "already searched earlier" â†’ SEARCH AGAIN with different query
   5. Verify search was executed before providing answer
   6. Base answer ONLY on search results, not general knowledge or previous searches

âš ï¸  EXAMPLE VIOLATIONS (DO NOT DO THIS):
   âŒ THOUGHT: "I already have a relevant snippet" â†’ ACTION: NONE
   âŒ THOUGHT: "Based on previous information" â†’ ACTION: NONE
   âŒ THOUGHT: "I know about few-shot learning" â†’ ACTION: NONE
   âŒ THOUGHT: "Since I have already received a relevant snippet from the indexed book" â†’ ACTION: NONE
   âŒ THOUGHT: "I searched earlier in this conversation" â†’ ACTION: NONE
   âŒ THOUGHT: "I can use information from previous search" â†’ ACTION: NONE

âš ï¸  CORRECT PATTERN (DO THIS):
   âœ… THOUGHT: "User asks about indexed content" â†’ ACTION: codebase_search
   âœ… THOUGHT: "Need to search book for X" â†’ ACTION: codebase_search
   âœ… THOUGHT: "Follow-up question needs different search angle" â†’ ACTION: codebase_search
   âœ… THOUGHT: "New question requires new search" â†’ ACTION: codebase_search
   âœ… Wait for search results â†’ THEN provide answer based on results

CRITICAL: If you answer an indexed content question without searching first, your answer is INVALID and will mislead the user!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOOL SELECTION RULES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Use codebase_search when:
- User asks "how does X work" about code functionality in THIS project
- User asks "where is X implemented" or "find code that does X"
- User asks about project architecture or structure
- User wants to understand existing code in the indexed codebase
- Questions start with: "explain", "show me", "how does", "where is", "what does"
- User wants to find functions, classes, or implementations
- NOTE: This tool is DISABLED by default - if it returns error, tell user to index codebase first
- PRIORITY: If asking about THIS project's code â†’ try codebase_search FIRST before file_operations

Use code_executor when:
- User asks to run/test/execute Python code
- User wants to debug code snippets
- User asks "what does this code output"
- User provides code and asks to try it

Use web_search when:
- User explicitly asks to "search" for something online
- User wants to find information on the web
- User asks about current events or documentation online
- User needs information about external libraries or best practices
- Information is NOT available in the indexed codebase
- NOTE: Web search is DISABLED by default - inform user if tool returns disabled error

Use file_operations when:
- User asks to read a SPECIFIC known file path
- User wants to write/create/modify a file
- User wants to list directory contents
- User asks about files without wanting to understand code (just list/read/write operations)
- NOTE: If user wants to UNDERSTAND code, prefer codebase_search over file_operations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš¨ TOOL INPUT JSON FORMAT - ABSOLUTELY CRITICAL:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ALL tools require VALID JSON format for ACTION_INPUT. Common mistakes:

âŒ WRONG: codebase_search
          ACTION_INPUT: "prompting techniques" in the book
          ERROR: This is NOT valid JSON!

âŒ WRONG: codebase_search
          ACTION_INPUT: prompting techniques
          ERROR: This is NOT valid JSON!

âœ… CORRECT: codebase_search
            ACTION_INPUT: {{"query": "prompting techniques"}}
            SUCCESS: Proper JSON with required "query" field

âŒ WRONG: file_operations
          ACTION_INPUT: list_files /path
          ERROR: This is NOT valid JSON!

âœ… CORRECT: file_operations
            ACTION_INPUT: {{"action": "list", "path": "/path"}}
            SUCCESS: Proper JSON with required fields

CRITICAL JSON RULES:
1. ACTION_INPUT must ALWAYS be valid JSON
2. Use double braces {{{{"}}}} in examples (gets unescaped to {{}})
3. Use double quotes " for strings, not single quotes '
4. Include ALL required fields for each tool
5. Check the tool's description at the top to see required format

If you're not sure about the format, look at the tool examples at the top of this prompt!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRITICAL RULES - FOLLOW EXACTLY:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Always start with THOUGHT to explain your reasoning
2. Use ACTION to specify a tool (or NONE if you're ready to answer)
3. Provide ACTION_INPUT as valid JSON (see JSON FORMAT section above)
4. NEVER use placeholder paths like "/path/to/file" - always use real paths from above
5. If you don't know a specific filename, list the directory first

âš ï¸  ANTI-SPECULATION RULES - CRITICAL:
   - NEVER use speculation words: "likely", "possibly", "presumably", "may contain", "probably", "might be", "appears to", "seems to"
   - If you're guessing about directory/file contents from names alone, you are SPECULATING (forbidden!)
   - WRONG: "agent/ likely contains agent-related code"
   - WRONG: "core/ possibly has core functionality"
   - WRONG: "This file may contain the implementation"
   - CORRECT: List/read the directory/file FIRST, then state facts: "agent/ contains X.py which implements Y (I read this file)"
   - If you don't have the information yet, say "I need to read X to confirm" - don't guess
   - When explaining architecture/code: you MUST read documentation files (README.md, ARCHITECTURE.md, etc.) BEFORE answering
   - Directory listings alone are NOT sufficient to explain "how things work" - you must read the actual code/docs

âš ï¸  MULTI-STEP RULES (when user says "THEN", "AND", or lists multiple tasks):
   - Count the steps the user requests
   - Complete ALL steps before providing final ANSWER
   - After each tool result, check: "Did I complete all requested steps?"
   - If NO: call the next tool (leave ANSWER empty)
   - If YES: provide final ANSWER summarizing all results
   - Example: "List files THEN read agent.py" = 2 steps, need 2 tool calls before ANSWER

âš ï¸  ANSWER EXTRACTION RULES (don't dump full files):
   - When user asks specific question about file (e.g., "what is the primary model?")
   - Read the file, EXTRACT the specific answer from tool result
   - Provide ONLY the answer, not the full file contents
   - Example: Config has 45 lines, user asks for one setting â†’ answer with that ONE setting

âš ï¸  NO HALLUCINATION RULES (only describe what you actually see):
   - NEVER describe code functions/features without reading the file first
   - NEVER claim "the code uses X" unless you SEE X in the tool result
   - If asked about code, you MUST read it first, then describe ONLY what's in the result
   - Say "Based on the actual code I see..." to indicate you read it
   - If unsure, say "I would need to read the file to confirm"

âš ï¸  ERROR RECOVERY RULES - NEVER GIVE UP ON ERRORS:
   - When a tool returns an error (starts with âœ—), DO NOT provide an ANSWER
   - Read the error message to understand what went wrong
   - Retry with the CORRECT tool name and input format
   - Common errors:
     â€¢ "Tool 'X' not found" â†’ Check available tools list and use correct name
     â€¢ "Invalid JSON" â†’ Fix your ACTION_INPUT to be valid JSON
     â€¢ "Path not allowed" â†’ Use paths from allowed_paths list
   - You can retry up to max_iterations times - use them!
   - Only provide final ANSWER after successful tool execution or if truly unable to proceed

âš ï¸  COMPLETE INVESTIGATION RULES - READ BEFORE ANSWERING:
   - If you mention a file in your THOUGHT but haven't read it yet, READ IT FIRST
   - NEVER say "the code is in X file" without actually reading X file
   - NEVER say "X is implemented in Y" without reading Y to verify
   - When you identify the relevant file, you MUST read it before answering
   - Example violations:
     â€¢ THOUGHT: "The implementation is in core/agent.py" + ACTION: NONE â†’ WRONG!
     â€¢ Correct: "The implementation is in core/agent.py" + ACTION: file_operations to read it
   - If user asks "how does X work", you must READ the actual implementation
   - Surface-level descriptions without reading the code are NOT acceptable
   - Only provide ANSWER after you've read all relevant files you identified

âš ï¸  USE FILE CONTENTS AFTER READING - CRITICAL:
   - When you successfully read a file (tool returns âœ“ Read X lines), you MUST use that content
   - NEVER ignore file contents you just read and provide generic answers instead
   - The file content is shown in the tool result - extract information from it
   - If user asks "how does X work" and you just read X's implementation, answer using THAT code
   - WRONG: Read core/agent.py â†’ ignore it â†’ give generic AI agent explanation
   - CORRECT: Read core/agent.py â†’ extract details about ReAct, StateGraph, nodes â†’ answer with specifics
   - After reading a file, your answer MUST reference what you saw in that file
   - If the question is about THIS project's code and you read the relevant file, do NOT fall back to general knowledge
   - Start your answer with "Based on the code I read in [filename]..." to ensure you're using the file content

âš ï¸  CODEBASE_SEARCH RESULT USAGE - CRITICAL:
   - When codebase_search returns successful results with code snippets, ANSWER DIRECTLY from those snippets
   - DO NOT read the entire source file after getting search results - the snippets ARE the answer
   - Search results contain: file path, function/class name, line numbers, similarity score, code snippet
   - These code snippets are specifically selected as relevant to the query - use them directly
   - WRONG pattern: codebase_search â†’ gets results â†’ reads entire 15,000-line file â†’ gets lost
   - CORRECT pattern: codebase_search â†’ gets results with snippets â†’ answers from snippets
   - Only read the full file if:
     1. Search results don't contain enough detail, OR
     2. User explicitly asks to read the file, OR
     3. You need to see context around the snippet

âš ï¸  COMPLETE SNIPPET EXTRACTION - ABSOLUTELY CRITICAL:
   - When analyzing search result snippets, you MUST extract ALL relevant information, not just the first mention
   - WRONG: Reading "The formats are XML and YAML. Another format is JSON..." â†’ only mentioning XML and YAML
   - CORRECT: Reading entire snippet â†’ extracting ALL formats: XML, YAML, JSON
   - Look for enumeration patterns that indicate multiple items:
     â€¢ "Another...", "Additionally...", "Also...", "Furthermore..."
     â€¢ "In addition to...", "As well as...", "Moreover..."
     â€¢ Numbered lists: "1. X, 2. Y, 3. Z"
     â€¢ "Both X and Y", "Either X or Y", "X, Y, and Z"
   - When snippet mentions multiple items (formats, methods, techniques, etc.), include ALL of them in your answer
   - Read the ENTIRE snippet before answering, don't stop after the first sentence
   - If the snippet says "The most suitable formats are XML and YAML. Both are common... Another markup language that should feature heavily is JSON...", your answer MUST include XML, YAML, AND JSON
   - Common mistake: Extracting only the first 1-2 items from a list and ignoring the rest
   - FIX: Read the complete snippet, identify all enumerated items, include them all in your answer

   Example of WRONG extraction (only partial):
     â€¢ Snippet: "The suitable formats are XML and YAML. Both are common in technical documents. Another markup language is JSON. At one point, we would have recommended against JSON, but OpenAI has made their models generate JSON accurately."
     â€¢ WRONG ANSWER: "The recommended formats are XML and YAML"
     â€¢ WHY WRONG: You ignored JSON mentioned later in the snippet

   Example of CORRECT extraction (complete):
     â€¢ Same snippet as above
     â€¢ CORRECT ANSWER: "The recommended formats are XML, YAML, and JSON. XML and YAML are suitable for structured documents because they're common in technical documents where precision is important. JSON is also recommended, especially for OpenAI models, because OpenAI has optimized their models for accurate JSON generation."
     â€¢ WHY CORRECT: Extracted ALL three formats and their reasoning

   CRITICAL RULE: If you see "another", "also", "additionally", or similar words in the snippet, you MUST continue reading and include those additional items in your answer!

âš ï¸  TOOL HALLUCINATION PREVENTION - ABSOLUTELY CRITICAL:

   ğŸš¨ BEFORE EVERY ACTION, CHECK THIS LIST ğŸš¨

   The ONLY valid tools are:
   {", ".join([tool.name for tool in self.tools])}

   That's it. No other tools exist. These are the ONLY 6 tools available.

   FORBIDDEN TOOLS (these DON'T EXIST - NEVER use them):
   âŒ SEARCH_DOCUMENT_FOR_SECTIONS (doesn't exist!)
   âŒ SEARCH_FILE_CONTENTS (doesn't exist!)
   âŒ Extract (doesn't exist!)
   âŒ AnalyzeCode (doesn't exist!)
   âŒ FindPatterns (doesn't exist!)
   âŒ ParseJSON (doesn't exist!)
   âŒ SearchText (doesn't exist!)
   âŒ ReadDocument (doesn't exist!)

   CORRECT TOOL MAPPING (use these instead):
   â€¢ Want to search? â†’ Use codebase_search
   â€¢ Want to read file? â†’ Use file_operations
   â€¢ Want to run code? â†’ Use code_executor
   â€¢ Want web info? â†’ Use web_search
   â€¢ Want to find symbol? â†’ Use symbol_lookup
   â€¢ Want import graph? â†’ Use import_graph

   PRE-ACTION CHECK (do this BEFORE writing ACTION):
   1. Look at the tool name you're about to use
   2. Check if it's in the valid tools list above
   3. If NO â†’ Map it to a valid tool from the CORRECT TOOL MAPPING
   4. If YES â†’ Proceed with that tool

   If you get error "Tool 'X' not found":
   1. DO NOT try to use 'X' again
   2. Look at the valid tools list above
   3. Pick the correct tool from that list
   4. Retry with the CORRECT tool name

âš ï¸  ANSWER RULES - THIS IS CRITICAL:
   - When you call a tool, leave ANSWER empty on that same response
   - After you receive the tool result, you MUST provide an ANSWER in the NEXT response
   - DO NOT call the same tool twice with the same input
   - Use ACTION: NONE when providing your final ANSWER
   - NEVER claim an action succeeded unless you SEE the tool output confirming it
   - If user asks to CREATE/WRITE a file, you MUST use ACTION: file_operations with "action": "write"
   - DO NOT say "I created the file" unless the tool output shows "âœ“ Wrote X lines"

âš ï¸  TOOL OUTPUT TRUST RULES - CRITICAL FOR ACCURACY:
   - Tools are AUTHORITATIVE and ACCURATE - trust their output completely
   - When a tool provides counts, totals, or statistics, USE THOSE NUMBERS DIRECTLY
   - DO NOT manually recount items from tool output - the tool already counted correctly
   - DO NOT verify or double-check numerical data provided by tools
   - CRITICAL: When tool output starts with "âœ“ Found X file(s)", use that EXACT number X
   - DO NOT count the file paths listed below the count - the tool already counted them
   - Example: If tool says "âœ“ Found 11 file(s)", report "11 files" - don't count the list yourself
   - Example: If tool says "5 directories, 24 files", use those exact numbers in your answer
   - WRONG: "Based on file paths provided, I count 4 files" - you should use the tool's count instead
   - RIGHT: "Tool found 5 files in tools/ directory" - you used the tool's count directly
   - If you need to categorize results, use the file paths to group them, but trust the overall count
   - Tools handle counting, parsing, and statistics - your job is to interpret and present their results

âš ï¸  ANSWER FORMATTING - COUNTS vs LISTS:
   - When user asks for "count", "number", "how many": provide ONLY the count, NOT the full list
   - When user asks to "list", "show", "display": provide the individual items
   - Example: "How many Python files?" â†’ Answer: "5 Python files" (NOT list of all 5 files)
   - Example: "List Python files" â†’ Answer: List all file names
   - Tool may return both count AND list - read the user question to decide what to include in ANSWER

âš ï¸  MULTI-PART QUESTION RULES - ANSWER ALL PARTS:
   - Many questions have MULTIPLE components that need separate answers
   - Common multi-part patterns:
     â€¢ "Compare X and Y. When would you use each?" (2 parts: comparison + usage guidance)
     â€¢ "Explain X and Y, and how they differ" (3 parts: explain X, explain Y, differences)
     â€¢ "What is X? How does it work? When should I use it?" (3 parts: definition, mechanism, usage)
   - CRITICAL: Identify ALL parts of the question before answering
   - Address EVERY part explicitly in your final answer
   - If search results don't cover all parts, run ADDITIONAL targeted searches
   - Example breakdown:
     â€¢ Question: "Compare few-shot vs chain-of-thought. When would you use one over the other?"
     â€¢ Part 1: Compare (similarities and differences)
     â€¢ Part 2: When to use few-shot (specific scenarios)
     â€¢ Part 3: When to use chain-of-thought (specific scenarios)
     â€¢ All 3 parts MUST be in the answer!

âš ï¸  COMPARISON QUESTION RULES - BE COMPREHENSIVE:
   - "Compare X and Y" questions require structured analysis:
     1. Definition/description of X with key characteristics
     2. Definition/description of Y with key characteristics
     3. Similarities between X and Y (what they have in common)
     4. Differences between X and Y (how they diverge)
   - "When would you use X over Y" requires decision guidance:
     1. Specific scenarios where X is better (with reasons)
     2. Specific scenarios where Y is better (with reasons)
     3. Trade-offs and decision criteria
   - Consider running MULTIPLE targeted searches for comprehensive coverage:
     â€¢ First search: "X definition advantages disadvantages"
     â€¢ Second search: "Y definition advantages disadvantages"
     â€¢ Third search: "when to use X versus Y" or "X vs Y comparison"
   - WRONG: Single broad search, incomplete answer missing "when to use" section
   - CORRECT: Multiple focused searches, complete answer addressing all question parts

âš ï¸  ANSWER COMPLETENESS VALIDATION - SELF-CHECK BEFORE ANSWERING:
   - Before providing your final ANSWER, ask yourself:
     1. How many parts does the user's question have? (count them!)
     2. Did I address EVERY part in my answer? (verify each one)
     3. For comparison questions: Did I cover definitions, similarities, differences, AND usage guidance?
     4. For "when to use" questions: Did I provide specific scenarios and decision criteria?
   - If you realize you're missing information for any part:
     â€¢ DO NOT provide incomplete answer
     â€¢ Run additional targeted search for missing information
     â€¢ THEN provide complete answer covering all parts
   - Quality checklist for comparison + usage questions:
     âœ“ Defined both concepts clearly
     âœ“ Explained advantages of each
     âœ“ Explained challenges/limitations of each
     âœ“ Provided explicit "when to use X" guidance
     âœ“ Provided explicit "when to use Y" guidance
     âœ“ Mentioned any combinations or alternatives if relevant

Remember: You are running locally. All operations happen on the user's machine.
The examples above show the COMPLETE flow - notice how ANSWER is provided AFTER receiving tool results.

{self._get_skill_prompt_section()}
{self._get_subagent_prompt_section()}"""

    def _get_skill_prompt_section(self) -> str:
        """Generate system prompt section for available skills.

        Returns:
            Formatted string describing available skills, or empty string if none.
        """
        if self.skill_tool is None:
            return ""

        try:
            return self.skill_tool.generate_prompt_section()
        except Exception:
            return ""

    def _get_subagent_prompt_section(self) -> str:
        """Generate system prompt section for available sub-agents.

        Returns:
            Formatted string describing available sub-agents, or empty string if none.
        """
        if self.subagent_tool is None:
            return ""

        try:
            return self.subagent_tool.generate_prompt_section()
        except Exception:
            return ""

    def _parse_agent_output(self, output: str) -> Dict[str, str]:
        """Parse agent output into structured format.

        Expected format:
            THOUGHT: ...
            ACTION: tool_name or NONE
            ACTION_INPUT: ...
            ANSWER: ...

        Args:
            output: Raw LLM output

        Returns:
            Dictionary with thought, action, action_input, answer

        Raises:
            AgentParsingError: If output format is invalid
        """
        try:
            parsed = {
                "thought": "",
                "action": "NONE",
                "action_input": "",
                "answer": ""
            }

            # Extract THOUGHT
            thought_match = re.search(r'THOUGHT:\s*(.+?)(?=\nACTION:|$)', output, re.DOTALL)
            if thought_match:
                parsed["thought"] = thought_match.group(1).strip()

            # Extract ACTION
            action_match = re.search(r'ACTION:\s*(\S+)', output)
            if action_match:
                parsed["action"] = action_match.group(1).strip()

            # Extract ACTION_INPUT
            input_match = re.search(r'ACTION_INPUT:\s*(.+?)(?=\nANSWER:|$)', output, re.DOTALL)
            if input_match:
                parsed["action_input"] = input_match.group(1).strip()

            # Extract ANSWER
            answer_match = re.search(r'ANSWER:\s*(.+?)$', output, re.DOTALL)
            if answer_match:
                parsed["answer"] = answer_match.group(1).strip()

            return parsed

        except Exception as e:
            raise AgentParsingError(f"Failed to parse agent output: {e}") from e

    def _force_synthesis(self, state: AgentState) -> str:
        """Force synthesis of gathered information when agent hasn't provided natural answer.

        This is called when:
        1. Agent hits max iterations without providing ANSWER
        2. Agent provides ANSWER but it's just raw tool output

        Args:
            state: Current agent state with tool results

        Returns:
            Synthesized natural language answer
        """
        try:
            user_query = state['messages'][-1] if state['messages'] else ''

            # Gather all successful tool results
            tool_summaries = []
            for tc in state["tool_calls"]:
                if tc["output"] and not tc["output"].startswith("âœ—"):
                    output = tc["output"]

                    # Don't truncate file reads - they contain the key information for synthesis
                    # For other tools, limit to avoid overwhelming the synthesis prompt
                    if tc['tool_name'] == 'file_operations' and 'âœ“ Read' in output:
                        # Keep full file content for synthesis (no truncation)
                        pass
                    else:
                        # Other tools - keep truncation at 500 chars
                        if len(output) > 500:
                            output = output[:500] + "... (truncated)"

                    tool_summaries.append(f"â€¢ {tc['tool_name']}: {output}")

            # If no successful tool results, provide a helpful message
            if not tool_summaries:
                return "I attempted to gather information but encountered issues with the tools. Could you please rephrase your question or provide more details?"

            # Create focused synthesis prompt
            synthesis_prompt = f"""You have gathered the following information through tool execution:

{chr(10).join(tool_summaries)}

User's original question: "{user_query}"

TASK: Based ONLY on the information above, provide a clear, natural language answer to the user's question.

CRITICAL RULES:
1. Use ONLY facts from the tool results above - NO speculation, NO guessing
2. FORBIDDEN WORDS: "likely", "possibly", "presumably", "may contain", "probably", "might be", "appears to", "seems to"
3. If you don't have information, say "Based on X, I can confirm Y" (be specific about what you DO know)
4. Synthesize into 2-4 sentences of DEFINITE factual statements
5. Do NOT include tool markers (âœ“, âœ—, JSON) - use natural language only
6. Do NOT say "the tool returned" or "based on the code in" - just state the facts
7. Be conversational but FACTUAL - if information is incomplete, acknowledge what's missing

WRONG: "The agent/ directory likely contains agent code"
RIGHT: "The agent/ directory contains X.py and Y.py which implement [specific functionality from tool results]"

Your evidence-based answer (NO speculation):"""

            # Call LLM to synthesize
            llm = self.model_manager.get_llm()
            response = llm.invoke(synthesis_prompt)

            # Clean up response
            answer = response.strip()

            # Remove any remaining tool markers
            for marker in ["âœ“", "âœ—", "ANSWER:", "THOUGHT:", "ACTION:"]:
                answer = answer.replace(marker, "")

            return answer.strip()

        except Exception as e:
            if self.logger:
                self.logger.error(f"Force synthesis failed: {e}")
            # Fallback to a helpful error message
            return f"I gathered information from {len(state['tool_calls'])} tools but encountered an error synthesizing the answer. Please try rephrasing your question."

    def _reasoning_node(self, state: AgentState) -> AgentState:
        """Reasoning node: Agent thinks about what to do.

        Args:
            state: Current agent state

        Returns:
            Updated state with new thought and action decision
        """
        try:
            # Check iteration limit
            if state["iteration"] >= self.max_iterations:
                if self.verbose:
                    print(f"\nâš  Reached max iterations ({self.max_iterations})")
                    print("   Forcing synthesis of gathered information...")

                # Force synthesis of gathered information instead of generic error
                state["finished"] = True
                state["final_answer"] = self._force_synthesis(state)
                return state

            # Build prompt with system message, conversation context, and current state
            conversation_context = self._build_conversation_context()
            state_context = self._build_state_context(state)

            # Check if we have recent tool results to show
            recent_tool_result = ""
            if state["tool_calls"] and state["tool_calls"][-1]["output"]:
                tool_output = state["tool_calls"][-1]["output"]

                # Check if the tool call resulted in an error
                is_error = tool_output.startswith("âœ—")

                if is_error:
                    # Tool failed - instruct agent to retry with correct parameters
                    instruction = f"""TOOL ERROR OCCURRED - DO NOT GIVE UP!

The tool call failed with an error. You MUST:
1. Read the error message carefully
2. Identify what went wrong (wrong tool name? wrong input format?)
3. Retry with the CORRECT tool name and input format
4. DO NOT provide an ANSWER yet - fix the error first

Error details below:"""
                else:
                    # Tool succeeded - determine next steps
                    user_query = state['messages'][-1] if state['messages'] else ''
                    step_keywords = user_query.lower().count(' then ') + user_query.lower().count(' and then ')
                    total_steps_needed = step_keywords + 1  # +1 for the first step
                    steps_completed = len([tc for tc in state["tool_calls"] if tc["output"] is not None and not tc["output"].startswith("âœ—")])

                    # Check if we just successfully read a file
                    last_tool_call = state["tool_calls"][-1]
                    read_file_successfully = (
                        last_tool_call["tool_name"] == "file_operations" and
                        tool_output.startswith("âœ“ Read") and
                        "lines from" in tool_output
                    )

                    if self.verbose and read_file_successfully:
                        print(f"\nğŸ” DETECTED: File read successfully - adding CRITICAL instruction")
                        print(f"   Tool: {last_tool_call['tool_name']}")
                        print(f"   Output starts with: {tool_output[:50]}")

                    if steps_completed < total_steps_needed:
                        instruction = f"User asked for {total_steps_needed} steps. You completed {steps_completed}. Call the NEXT tool now (leave ANSWER empty)."
                    elif read_file_successfully:
                        # Just read a file - FORCE agent to use its content
                        if self.verbose:
                            print(f"   ğŸš¨ INJECTING CRITICAL INSTRUCTION TO FORCE FILE CONTENT USAGE")
                        instruction = """ğŸš¨ FILE READ SUCCESSFULLY - USE THIS CONTENT TO ANSWER! ğŸš¨

The tool just read a file. The FULL FILE CONTENT is in the tool output below.

YOU ARE STRICTLY FORBIDDEN FROM:
âŒ Answering from general knowledge or making assumptions
âŒ Saying "typically" or "usually" or "generally"
âŒ Providing textbook explanations instead of using the actual code
âŒ Claiming "Based on standard practices..." - NO! Use the actual file content!

YOU MUST:
âœ… Extract the answer from the file content below
âœ… Reference specific details (function names, classes, line numbers)
âœ… Start your ANSWER with: "Based on the code in [filename], ..."
âœ… Quote or describe what you actually see in the tool result

This is a test of your ability to follow instructions. Generic answers = FAILURE."""
                    else:
                        instruction = "You completed ALL steps. Provide your final ANSWER now with ACTION: NONE."

                recent_tool_result = f"""

âš ï¸ âš ï¸ âš ï¸ CRITICAL - READ THIS FIRST âš ï¸ âš ï¸ âš ï¸
{instruction}

Tool Result:
{tool_output}"""

            # Detect if we're potentially looping (same tool called multiple times)
            loop_warning = ""
            if len(state["tool_calls"]) >= 2:
                last_call = state["tool_calls"][-1]
                second_last_call = state["tool_calls"][-2]

                if (last_call["tool_name"] == second_last_call["tool_name"] and
                    last_call["input"] == second_last_call["input"]):
                    loop_warning = f"""
âš ï¸ WARNING: You just called {last_call['tool_name']} with the SAME input twice!
You already have the result. DO NOT call this tool again.
You MUST provide an ANSWER now based on the tool result you received."""

            # Retrieve relevant memories if enabled
            memory_context = ""
            if self.long_term_memory:
                try:
                    user_query = state['messages'][-1] if state['messages'] else ''
                    relevant_memories = self.long_term_memory.retrieve_relevant(
                        query=user_query,
                        top_k=5,
                        min_importance=0.3
                    )

                    if relevant_memories:
                        memory_lines = []
                        for mem in relevant_memories:
                            memory_lines.append(
                                f"  â€¢ [{mem.memory_type}] {mem.content} (importance: {mem.importance:.2f})"
                            )

                        memory_context = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
RELEVANT MEMORIES (from previous sessions):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{chr(10).join(memory_lines)}

"""
                except Exception as e:
                    if self.logger:
                        self.logger.warning(f"Failed to retrieve memories: {e}")

            prompt = f"""{self._get_system_prompt()}

{memory_context}{conversation_context}

{state_context}{recent_tool_result}

{loop_warning}

User Query: {state['messages'][-1] if state['messages'] else 'No query'}

Now, think step by step and respond with THOUGHT, ACTION, ACTION_INPUT, and ANSWER.

CRITICAL RULES:
1. If you just received a tool result above, you MUST provide an ANSWER based on that result
2. DO NOT call the same tool twice in a row with the same input
3. After getting a file's contents or other tool result, immediately provide your ANSWER
4. Only use ACTION: NONE when you're ready to give the final ANSWER"""

            # Get LLM response
            llm = self.model_manager.get_llm()
            response = llm.invoke(prompt)

            # Parse response
            parsed = self._parse_agent_output(response)

            # Validate parsed output - ensure non-empty fields
            if not parsed["thought"]:
                parsed["thought"] = "Continuing with the task"

            # Add thought to state
            state["thoughts"].append(parsed["thought"])

            if self.verbose:
                print(f"\nğŸ’­ THOUGHT: {parsed['thought']}")
                print(f"ğŸ¯ ACTION: {parsed['action']}")
                if parsed['action_input']:
                    print(f"ğŸ“¥ INPUT: {parsed['action_input'][:100]}...")
                if parsed['answer']:
                    print(f"ğŸ’¬ ANSWER: {parsed['answer'][:150]}...")

            # LOOP DETECTION: Check if agent is trying to call the same tool again
            if parsed["action"] != "NONE" and len(state["tool_calls"]) >= 1:
                last_successful_call = state["tool_calls"][-1]

                # If trying to repeat the exact same call, force an answer
                if (parsed["action"] == last_successful_call["tool_name"] and
                    parsed["action_input"] == last_successful_call["input"] and
                    last_successful_call["output"] is not None):

                    if self.verbose:
                        print(f"\nğŸš« LOOP DETECTED: Agent tried to repeat the same tool call")
                        print(f"   Forcing answer based on existing result...")

                    # Extract the tool result
                    tool_result = last_successful_call["output"]

                    # Check if this looks like a raw file dump (long content with file markers)
                    if (tool_result.startswith("âœ“ Read") and len(tool_result) > 500):
                        # Large file read - try to extract relevant information
                        user_query = state['messages'][-1] if state['messages'] else ''

                        # Give ONE MORE CHANCE with ultra-focused extraction prompt
                        extraction_prompt = f"""ğŸš¨ CRITICAL TASK: Extract answer from file content ğŸš¨

User Question: "{user_query}"

The file was already read. Your job is to extract the answer from the content below.

STRICT RULES:
1. Base answer ONLY on the file content below
2. DO NOT say "the file is too large" - extract what's needed
3. DO NOT provide generic answers - use specific code details
4. Reference actual function/class names, line numbers from the content
5. If the answer isn't in the file, say "The file doesn't contain information about [topic]"

File Content:
{tool_result}

Provide a concise answer:"""

                        # Call LLM with focused extraction prompt
                        try:
                            llm = self.model_manager.get_llm()
                            extraction_response = llm.invoke(extraction_prompt)

                            # Use the full response as answer (it should be focused)
                            state["final_answer"] = extraction_response.strip()

                            if self.verbose:
                                print(f"   âœ… Extracted answer from large file using focused prompt")

                        except Exception as e:
                            if self.logger:
                                self.logger.error(f"Failed to extract from large file: {e}")
                            state["final_answer"] = f"I read the file but encountered an error during extraction: {str(e)}"

                    else:
                        # Small result - ok to use directly
                        state["final_answer"] = tool_result

                    state["finished"] = True
                    return state

            # Store action for tool execution
            if parsed["action"] != "NONE":
                # Always add the tool call, even if invalid
                # Tool execution node will handle validation
                state["tool_calls"].append({
                    "tool_name": parsed["action"],
                    "input": parsed["action_input"],
                    "output": None  # Will be filled by tool execution node
                })

            # Check if agent provided final answer
            # Only mark finished if there's an answer AND no pending tool calls
            if parsed["answer"]:
                # Check if there are pending tool calls
                pending_tools = [tc for tc in state["tool_calls"] if tc["output"] is None]
                if not pending_tools:
                    # VALIDATION: Check if agent mentioned files it hasn't read
                    import re
                    mentioned_files = set()
                    read_files = set()

                    # Extract file paths mentioned in thought and answer
                    combined_text = parsed["thought"] + " " + parsed["answer"]
                    # Look for patterns like "core/agent.py", "/path/to/file.py", "file.py"
                    file_patterns = re.findall(r'[\w/]+\.py', combined_text)
                    for pattern in file_patterns:
                        # Normalize path
                        if pattern.startswith('/'):
                            mentioned_files.add(pattern)
                        else:
                            # Relative path - add with cwd
                            from pathlib import Path
                            full_path = str(Path.cwd() / pattern)
                            mentioned_files.add(full_path)

                    # Check which files were actually read
                    for tc in state["tool_calls"]:
                        if tc["tool_name"] == "file_operations" and tc["output"] and tc["output"].startswith("âœ“ Read"):
                            # Extract path from successful read operations
                            try:
                                input_data = json.loads(tc["input"])
                                if input_data.get("action") == "read":
                                    path = input_data.get("path", "")
                                    read_files.add(path)
                            except (json.JSONDecodeError, KeyError, TypeError):
                                # Skip malformed tool call entries
                                pass

                    # Find unread but mentioned files
                    unread_files = mentioned_files - read_files

                    if unread_files and self.verbose:
                        # Warn but don't block - agent should learn from improved prompts
                        print(f"\nâš ï¸  WARNING: Agent may have answered without reading:")
                        for f in unread_files:
                            print(f"   - {f}")

                    if unread_files and self.logger:
                        self.logger.warning(f"Agent mentioned unread files: {unread_files}")

                    # No pending tools, so this is the final answer
                    # Quality check: ensure this isn't raw tool output OR speculation
                    answer = parsed["answer"]

                    # Tool output markers (check first 200 chars)
                    tool_markers = ["âœ“ Read", "âœ“ Found", "âœ“ Wrote", "âœ“ Contents", "{", "success"]

                    # Mechanical phrasing that indicates file dump instead of synthesis
                    mechanical_phrases = [
                        "Based on the code in",
                        "According to the file",
                        "The file shows",
                        "The file contains",
                        "Based on the directory listing"
                    ]

                    # Speculation words (check entire answer for these)
                    speculation_words = [
                        "likely", "possibly", "presumably", "may contain",
                        "probably", "might be", "appears to", "seems to",
                        "may be", "could be", "perhaps"
                    ]

                    # Check for quality issues
                    has_tool_marker = any(marker in answer[:200] for marker in tool_markers)
                    has_mechanical = any(phrase in answer[:200] for phrase in mechanical_phrases)
                    has_speculation = any(word in answer.lower() for word in speculation_words)

                    if has_tool_marker or has_mechanical or has_speculation:
                        if self.verbose:
                            if has_tool_marker:
                                print(f"\nâš ï¸  Quality check failed - answer contains raw tool output")
                            if has_mechanical:
                                print(f"\nâš ï¸  Quality check failed - mechanical phrasing detected")
                            if has_speculation:
                                # Find which speculation words were used
                                found_words = [w for w in speculation_words if w in answer.lower()]
                                print(f"\nâš ï¸  Quality check failed - speculation detected: {', '.join(found_words[:3])}")
                            print(f"   Forcing re-synthesis...")

                        # Force synthesis to get natural language without speculation
                        state["final_answer"] = self._force_synthesis(state)
                    else:
                        # Answer looks good
                        state["final_answer"] = answer

                    state["finished"] = True
                # else: there are pending tools, so don't finish yet - let them execute first

            state["iteration"] += 1

            return state

        except Exception as e:
            if self.logger:
                self.logger.error(f"Reasoning node error: {e}")

            state["finished"] = True
            state["final_answer"] = f"I encountered an error while reasoning: {str(e)}"
            return state

    def _tool_execution_node(self, state: AgentState) -> AgentState:
        """Tool execution node: Execute the selected tool.

        Args:
            state: Current agent state

        Returns:
            Updated state with tool results
        """
        try:
            # Get the most recent tool call that hasn't been executed
            pending_calls = [tc for tc in state["tool_calls"] if tc["output"] is None]

            if not pending_calls:
                return state

            tool_call = pending_calls[-1]
            tool_name = tool_call["tool_name"]
            tool_input = tool_call["input"]

            if self.verbose:
                print(f"\nğŸ”§ Executing: {tool_name}")

            # Get tool
            tool = self.tool_map.get(tool_name)
            if not tool:
                available_tools = ", ".join(self.tool_map.keys())
                error_msg = f"Tool '{tool_name}' not found. Available tools: {available_tools}"
                tool_call["output"] = f"âœ— {error_msg}"
                if self.verbose:
                    print(f"âœ— Error: {error_msg}")
                if self.logger:
                    self.logger.warning(error_msg)
                return state

            # Execute tool
            try:
                result = tool._run(tool_input)
                tool_call["output"] = result

                if self.verbose:
                    print(f"âœ“ Result: {result[:200]}..." if len(result) > 200 else f"âœ“ Result: {result}")

                # Log to conversation
                self.conversation.add_tool_message(
                    result,
                    tool_name=tool_name,
                    action=tool_call.get("action", "execute")
                )

            except Exception as e:
                error_msg = f"Tool execution failed: {str(e)}"
                tool_call["output"] = f"âœ— {error_msg}"
                if self.logger:
                    self.logger.error(error_msg)

            return state

        except Exception as e:
            if self.logger:
                self.logger.error(f"Tool execution node error: {e}")

            # Mark last tool call as failed
            if state["tool_calls"]:
                state["tool_calls"][-1]["output"] = f"âœ— Error: {str(e)}"

            return state

    def _observation_node(self, state: AgentState) -> AgentState:
        """Observation node: Process tool results.

        Args:
            state: Current agent state

        Returns:
            Updated state after observing tool results
        """
        try:
            # Get the most recent tool call
            if not state["tool_calls"]:
                return state

            tool_call = state["tool_calls"][-1]

            if self.verbose:
                print(f"\nğŸ‘ Observing results from {tool_call['tool_name']}...")

            # Tool result is already in tool_call["output"]
            # Agent will see it in the next reasoning step

            return state

        except Exception as e:
            if self.logger:
                self.logger.error(f"Observation node error: {e}")
            return state

    def _should_execute_tool(self, state: AgentState) -> str:
        """Decision: Should we execute a tool?

        Args:
            state: Current agent state

        Returns:
            "tool_execution" if there's a pending tool call, "end" otherwise
        """
        # Check if finished
        if state["finished"]:
            return "end"

        # Check if there's a pending tool call
        pending = [tc for tc in state["tool_calls"] if tc["output"] is None]
        if pending:
            return "tool_execution"

        return "end"

    def _should_continue(self, state: AgentState) -> str:
        """Decision: Should we continue reasoning?

        Args:
            state: Current agent state

        Returns:
            "reasoning" to continue, "end" if finished
        """
        if state["finished"] or state["iteration"] >= self.max_iterations:
            return "end"

        return "reasoning"

    def _build_conversation_context(self) -> str:
        """Build conversation context from recent messages.

        Returns:
            Formatted conversation history
        """
        messages = self.conversation.get_messages(limit=5)
        if not messages:
            return ""

        context_parts = ["Recent Conversation:"]
        for msg in messages:
            role = msg['role'].upper()
            content = msg['content'][:200]  # Limit length
            if len(msg['content']) > 200:
                content += "..."
            context_parts.append(f"{role}: {content}")

        return "\n".join(context_parts)

    def _build_state_context(self, state: AgentState) -> str:
        """Build context from current agent state.

        Args:
            state: Current agent state

        Returns:
            Formatted state context
        """
        parts = []

        if state["thoughts"]:
            parts.append("Previous Thoughts:")
            for i, thought in enumerate(state["thoughts"][-3:], 1):  # Last 3 thoughts
                parts.append(f"{i}. {thought}")

        if state["tool_calls"]:
            parts.append("\nPrevious Tool Calls:")
            for tc in state["tool_calls"][-3:]:  # Last 3 calls
                # Don't truncate tool output - agent needs full context to reason correctly
                output = tc['output'] if tc['output'] else 'pending'
                parts.append(f"- {tc['tool_name']}: {output}")

        if parts:
            return "\n".join(parts)

        return ""

    def run(self, user_input: str) -> Dict[str, Any]:
        """Run the agent with user input.

        Args:
            user_input: User's question or command

        Returns:
            Dictionary with output, thoughts, tool_calls, success, and error (if any)

        Example:
            >>> result = agent.run("List files in /path/to/dir")
            >>> print(result['output'])
            >>> print(result['thoughts'])
        """
        import time as time_module

        start_time = time_module.time()

        # Execute pre-query hooks
        if self.hook_manager:
            try:
                from hooks.base import HookType, HookContext
                pre_context = HookContext(
                    hook_type=HookType.PRE_QUERY,
                    input_data=user_input,
                    session_id=self.conversation.session_id if hasattr(self.conversation, 'session_id') else None,
                )
                pre_results = self.hook_manager.execute(pre_context)

                # Check if any hook wants to skip execution
                for result in pre_results:
                    if result.should_skip:
                        return {
                            "output": result.output or "Query skipped by hook",
                            "thoughts": [],
                            "tool_calls": [],
                            "iterations": 0,
                            "success": True,
                            "skipped_by_hook": True
                        }
                    # Allow hooks to modify input
                    if result.modified_input is not None:
                        user_input = result.modified_input
            except ImportError:
                pass  # Hooks not available

        try:
            # Add user message to conversation
            self.conversation.add_user_message(user_input)

            # Initialize state
            initial_state: AgentState = {
                "messages": [user_input],
                "thoughts": [],
                "tool_calls": [],
                "iteration": 0,
                "finished": False,
                "final_answer": None
            }

            if self.verbose:
                print(f"\n{'='*60}")
                print(f"ğŸ¤– Meton Agent Starting")
                print(f"Query: {user_input}")
                print(f"{'='*60}")

            # Run graph with custom recursion limit
            final_state = self.graph.invoke(
                initial_state,
                config={"recursion_limit": self.recursion_limit}
            )

            # Extract result
            output = final_state.get("final_answer", "No answer provided")

            # Ensure output is not None or empty
            if not output or output.strip() == "":
                # If we have tool results, use the last one
                if final_state["tool_calls"]:
                    last_result = final_state["tool_calls"][-1].get("output", "")
                    if last_result:
                        output = f"Task completed. {last_result}"
                    else:
                        output = "Task completed successfully."
                else:
                    output = "Task completed."

            # Check if output is just a tool result dump (starts with tool result markers)
            # This indicates the LLM failed to extract/summarize the answer
            if output.startswith("âœ“ Read") or output.startswith("âœ“ Contents") or output.startswith("âœ“ Wrote"):
                # The agent dumped the tool output instead of answering the question
                # Check if there's a user query that asks a specific question
                user_query = final_state['messages'][-1] if final_state['messages'] else ''
                if any(keyword in user_query.lower() for keyword in ['what', 'how', 'why', 'explain', 'tell me']):
                    # User asked a question but got a file dump - provide a helpful message
                    output = "I retrieved the file contents but didn't properly analyze them to answer your question. Please try asking the question again, or ask me to search for specific information within the file."

            # Add assistant response to conversation
            metadata = {
                "thoughts": len(final_state["thoughts"]),
                "tool_calls": len(final_state["tool_calls"]),
                "iterations": final_state["iteration"],
                "model": self.model_manager.current_model
            }
            self.conversation.add_assistant_message(output, metadata)

            # Store important interactions in long-term memory
            if self.long_term_memory and self._is_important_interaction(user_input, output, metadata):
                try:
                    importance = self._calculate_interaction_importance(user_input, output, metadata)
                    tags = self._extract_tags_from_query(user_input)

                    # Create memory content
                    memory_content = f"Q: {user_input[:200]}"
                    if len(output) > 200:
                        memory_content += f"\nA: {output[:200]}..."
                    else:
                        memory_content += f"\nA: {output}"

                    # Store memory
                    self.long_term_memory.store_memory(
                        content=memory_content,
                        memory_type="conversation",
                        context={
                            "tool_calls": metadata["tool_calls"],
                            "iterations": metadata["iterations"],
                            "model": metadata["model"]
                        },
                        importance=importance,
                        tags=tags
                    )

                    if self.logger:
                        self.logger.debug(f"Stored interaction in long-term memory (importance: {importance:.2f})")
                except Exception as e:
                    if self.logger:
                        self.logger.warning(f"Failed to store memory: {e}")

            if self.verbose:
                print(f"\n{'='*60}")
                print(f"âœ… Agent Finished")
                print(f"Iterations: {final_state['iteration']}")
                print(f"{'='*60}\n")

            result = {
                "output": output,
                "thoughts": final_state["thoughts"],
                "tool_calls": final_state["tool_calls"],
                "iterations": final_state["iteration"],
                "success": True
            }

            # Execute post-query hooks (success case)
            duration = time_module.time() - start_time
            if self.hook_manager:
                try:
                    from hooks.base import HookType, HookContext
                    post_context = HookContext(
                        hook_type=HookType.POST_QUERY,
                        input_data=user_input,
                        output_data=output,
                        success=True,
                        duration_seconds=duration,
                        session_id=self.conversation.session_id if hasattr(self.conversation, 'session_id') else None,
                        metadata={
                            "iterations": final_state["iteration"],
                            "tool_calls_count": len(final_state["tool_calls"]),
                        }
                    )
                    self.hook_manager.execute(post_context)
                except ImportError:
                    pass  # Hooks not available

            return result

        except Exception as e:
            error_msg = f"Agent execution failed: {str(e)}"

            if self.logger:
                self.logger.error(error_msg)

            self.conversation.add_assistant_message(
                f"I encountered an error: {error_msg}",
                {"error": True}
            )

            if self.verbose:
                print(f"\nâŒ Error: {error_msg}\n")

            result = {
                "output": error_msg,
                "thoughts": [],
                "tool_calls": [],
                "iterations": 0,
                "success": False,
                "error": str(e)
            }

            # Execute post-query hooks (error case)
            duration = time_module.time() - start_time
            if self.hook_manager:
                try:
                    from hooks.base import HookType, HookContext
                    post_context = HookContext(
                        hook_type=HookType.POST_QUERY,
                        input_data=user_input,
                        success=False,
                        error=str(e),
                        duration_seconds=duration,
                        session_id=self.conversation.session_id if hasattr(self.conversation, 'session_id') else None,
                    )
                    self.hook_manager.execute(post_context)
                except ImportError:
                    pass  # Hooks not available

            return result

    def get_tool_names(self) -> List[str]:
        """Get names of available tools.

        Returns:
            List of tool names

        Example:
            >>> tools = agent.get_tool_names()
            >>> print(tools)
            ['file_operations']
        """
        return list(self.tool_map.keys())

    def add_tool(self, tool: BaseTool) -> None:
        """Add a tool to the agent.

        Args:
            tool: Tool to add

        Example:
            >>> new_tool = MyCustomTool()
            >>> agent.add_tool(new_tool)
        """
        self.tools.append(tool)
        self.tool_map[tool.name] = tool

        if self.logger:
            self.logger.info(f"Added tool: {tool.name}")

    def remove_tool(self, tool_name: str) -> bool:
        """Remove a tool from the agent.

        Args:
            tool_name: Name of tool to remove

        Returns:
            True if tool was removed, False if not found

        Example:
            >>> agent.remove_tool("file_operations")
            True
        """
        if tool_name in self.tool_map:
            del self.tool_map[tool_name]
            self.tools = [t for t in self.tools if t.name != tool_name]

            if self.logger:
                self.logger.info(f"Removed tool: {tool_name}")

            return True

        return False

    def get_info(self) -> Dict[str, Any]:
        """Get agent information.

        Returns:
            Dictionary with agent metadata

        Example:
            >>> info = agent.get_info()
            >>> print(info['model'])
            >>> print(info['tools'])
        """
        return {
            "model": self.model_manager.current_model,
            "tools": self.get_tool_names(),
            "max_iterations": self.max_iterations,
            "verbose": self.verbose,
            "conversation_messages": self.conversation.get_message_count()
        }

    # Long-term memory helper methods

    def _is_important_interaction(self, query: str, response: str, metadata: Dict) -> bool:
        """Determine if interaction should be stored in long-term memory.

        Args:
            query: User query
            response: Agent response
            metadata: Interaction metadata

        Returns:
            True if interaction is important enough to store
        """
        # Always store if user explicitly asks to remember
        if any(phrase in query.lower() for phrase in ['remember', 'don\'t forget', 'keep in mind']):
            return True

        # Store questions (learning opportunities)
        if any(word in query.lower() for word in ['what', 'how', 'why', 'when', 'where', 'explain']):
            return True

        # Store if user corrects or provides feedback
        if any(phrase in query.lower() for phrase in ['actually', 'incorrect', 'wrong', 'correct', 'prefer']):
            return True

        # Store if multiple tools were used (complex task)
        if metadata.get('tool_calls', 0) >= 2:
            return True

        # Store if it took multiple iterations (challenging task)
        if metadata.get('iterations', 0) >= 3:
            return True

        # Otherwise, don't store (routine interactions)
        return False

    def _calculate_interaction_importance(self, query: str, response: str, metadata: Dict) -> float:
        """Calculate importance score for interaction.

        Args:
            query: User query
            response: Agent response
            metadata: Interaction metadata

        Returns:
            Importance score (0.0 to 1.0)
        """
        importance = 0.5  # Base importance

        # Explicit remember request: high importance
        if any(phrase in query.lower() for phrase in ['remember', 'don\'t forget']):
            importance += 0.3

        # User feedback/corrections: high importance
        if any(phrase in query.lower() for phrase in ['actually', 'incorrect', 'prefer']):
            importance += 0.2

        # Complex queries: medium importance
        if len(query.split()) > 20:
            importance += 0.1

        # Multiple tool calls: indicates complexity
        tool_calls = metadata.get('tool_calls', 0)
        if tool_calls >= 3:
            importance += 0.2
        elif tool_calls >= 2:
            importance += 0.1

        # Many iterations: challenging problem
        iterations = metadata.get('iterations', 0)
        if iterations >= 5:
            importance += 0.1

        # Cap at 1.0
        return min(1.0, importance)

    def _extract_tags_from_query(self, query: str) -> List[str]:
        """Extract tags from query for categorization.

        Args:
            query: User query

        Returns:
            List of tags
        """
        tags = []
        query_lower = query.lower()

        # Programming languages
        languages = ['python', 'javascript', 'java', 'rust', 'go', 'c++', 'typescript']
        for lang in languages:
            if lang in query_lower:
                tags.append(lang)

        # Common topics
        topics = {
            'file': ['file', 'directory', 'folder', 'path'],
            'code': ['function', 'class', 'method', 'variable'],
            'web': ['http', 'api', 'request', 'endpoint'],
            'database': ['sql', 'database', 'query', 'table'],
            'test': ['test', 'testing', 'unittest'],
            'debug': ['debug', 'error', 'bug', 'fix'],
            'documentation': ['docs', 'documentation', 'readme'],
        }

        for tag, keywords in topics.items():
            if any(keyword in query_lower for keyword in keywords):
                tags.append(tag)

        return list(set(tags))  # Remove duplicates
